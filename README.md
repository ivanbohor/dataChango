# ðŸ›’ DataChango | Agregador Inteligente de Ofertas

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Selenium](https://img.shields.io/badge/Scraping-Selenium-green)
![Status](https://img.shields.io/badge/Status-Stable%20v1.0-success)

**DataChango** es una plataforma de inteligencia de datos que centraliza, normaliza y visualiza ofertas de los principales hipermercados de Argentina (**Coto, Jumbo, Carrefour y MasOnline**). 

El objetivo es simplificar la toma de decisiones del consumidor mediante un dashboard unificado que combina descuentos por categoria  y promociones bancarias, utilizando tÃ©cnicas de extracciÃ³n de datos con Selenium y Python.

ðŸ”— **Demo en vivo:** [datachangoweb.onrender.com](https://datachangoweb.onrender.com)

---

##  CaracterÃ­sticas TÃ©cnicas

###  1. Scraping HÃ­brido (DOM + VisiÃ³n Artificial)
- **ExtracciÃ³n HÃ­brida:** Combina selectores CSS/XPath tradicionales con **EasyOCR** (Optical Character Recognition) para leer ofertas "incrustadas" en imÃ¡genes.
- **NormalizaciÃ³n de Texto:** Algoritmos propios para estandarizar nombres de productos y categorÃ­as heterogÃ©neas.

###  2. ValidaciÃ³n y Filtrado Inteligente
- **DetecciÃ³n de "Falsas Ofertas":** LÃ³gica condicional para distinguir entre descuentos reales y financiaciÃ³n pura.
- **Anti-AlucinaciÃ³n:** Filtros de precisiÃ³n para evitar errores comunes de OCR y garantizar la integridad de los datos.

###  3. Arquitectura y Performance
- **OrquestaciÃ³n Modular:** Scripts de extracciÃ³n (`scrapers_bancarios/`, `run_all.py`) separados de la capa de visualizaciÃ³n (`app.py`).
- **Dependencias Optimizadas:** SeparaciÃ³n de entornos (`requirements.txt` ligero para Web vs `ori-requirements.txt` completo para Scraping) para despliegues Ã¡giles en la nube.
- **UX Avanzada:** Modal de "Lupa" con inyecciÃ³n JS personalizada y delegaciÃ³n de eventos para compatibilidad mÃ³vil/desktop.

---

## ðŸ“‚ Estructura del Proyecto

```text
datachango_root/
â”œâ”€â”€ app.py                      # Dashboard principal (Frontend Streamlit)
â”œâ”€â”€ run_promos.py               # Orquestador: Promos Bancarias
â”œâ”€â”€ run_all.py                  # Orquestador: Ofertas de Productos
â”œâ”€â”€ deploy_diario.py            # Script de automatizaciÃ³n (Scrape + Git Push)
â”‚
â”œâ”€â”€ scrapers_bancarios/         # Paquete: Scrapers de Bancos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bancarias_coto.py
â”‚   â”œâ”€â”€ bancarias_jumbo.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scraper_carrefour_general.py 
â”œâ”€â”€ scraper_coto.py             
â”œâ”€â”€ scraper_jumbo.py            
â”‚
â”œâ”€â”€ ofertas_*.json              # Base de datos (Archivos planos)
â”œâ”€â”€ promos_*.json               # Datos bancarios procesados
â”œâ”€â”€ requirements.txt            # Dependencias ligeras (Solo para Render/App)
â””â”€â”€ ori-requirements.txt        # Dependencias completas (Para correr Scrapers localmente)


## ðŸ“¦ InstalaciÃ³n y Uso Local
Pasos para levantar el proyecto completo en tu computadora:

1. Clonar el repositorio
2. Crear entorno virtual:
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

3. Instalar dependencias:
pip install -r ori-requirements.txt

4. Ejecutar Scrapers
python run_promos.py  # Bancos
python run_all.py     # Productos

5. Iniciar el Dashboard:
streamlit run app.py